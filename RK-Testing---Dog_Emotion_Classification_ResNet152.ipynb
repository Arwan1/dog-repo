# -*- coding: utf-8 -*-
"""Dog_Emotion_Classification_ResNet152.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/your_drive_link

# ResNet152-based Dog Emotion Classification

This notebook implements a ResNet152-based Convolutional Neural Network (CNN) for classifying dog emotions into 10 classes using a dataset of dog images. ResNet152, with its 152 layers and residual connections, is selected for its superior accuracy in image classification tasks. The workflow includes data loading from Google Drive, preprocessing with augmentation, transfer learning, training on a GPU, and evaluation. The goal is to maximize classification accuracy for deployment in emotion recognition applications.

### Workflow
1. Setup and import libraries.
2. Load and preprocess the dataset.
3. Define and configure ResNet152.
4. Train the model.
5. Evaluate and visualize results.

---

## Step 1: Setup and Import Libraries
"""

# Cell 1: Setup and Imports
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import ResNet152
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt
import os
from google.colab import drive

# Enable GPU
physical_devices = tf.config.list_physical_devices('GPU')
if physical_devices:
    tf.config.experimental.set_memory_growth(physical_devices[0], True)
print("TensorFlow version:", tf.__version__)
print("GPU available:", tf.test.is_gpu_available())

"""---

## Step 2: Load and Preprocess the Dataset"""

# Cell 2: Mount Google Drive and Load Data
drive.mount('/content/drive')

# Define dataset path
data_dir = '/content/drive/MyDrive/Arwan IRIS/2-EMOTION_IMAGE_DATASET'  # Update to your dataset path
if not os.path.exists(data_dir):
    raise Exception(f"Dataset folder {data_dir} not found.")

# Image parameters
img_height, img_width = 224, 224  # ResNet152 default input size
batch_size = 32
num_classes = 10  # Update based on your dataset (e.g., 10 dog emotions)

# Data augmentation and preprocessing
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2,
    preprocessing_function=tf.keras.applications.resnet.preprocess_input  # ResNet-specific preprocessing
)

# Training and validation generators
train_generator = train_datagen.flow_from_directory(
    data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

val_generator = train_datagen.flow_from_directory(
    data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

# Display class names
class_names = list(train_generator.class_indices.keys())
print("Class names:", class_names)
print("Training samples:", train_generator.samples)
print("Validation samples:", val_generator.samples)

"""---

## Step 3: Define and Configure ResNet152"""

# Cell 3: Define ResNet152 Model
def create_resnet152_model(num_classes):
    # Load pre-trained ResNet152 with ImageNet weights
    base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

    # Freeze base model layers
    base_model.trainable = False

    # Add custom classification head
    model = models.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dense(1024, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])

    return model

# Create and compile the model
model = create_resnet152_model(num_classes)
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Model summary
model.summary()

"""---

## Step 4: Train the Model"""

# Cell 4: Train the Model
epochs = 20  # Adjust based on convergence

# Callbacks for training
callbacks = [
    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
    tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/resnet152_dog_emotion_best.h5',
                                       monitor='val_accuracy', save_best_only=True)
]

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    validation_data=val_generator,
    validation_steps=val_generator.samples // batch_size,
    epochs=epochs,
    callbacks=callbacks
)

# Fine-tune (unfreeze some layers)
base_model = model.layers[0]
base_model.trainable = True
for layer in base_model.layers[:-20]:  # Fine-tune last 20 layers
    layer.trainable = False

# Recompile with lower learning rate
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Continue training
fine_tune_epochs = 10
history_fine = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    validation_data=val_generator,
    validation_steps=val_generator.samples // batch_size,
    epochs=fine_tune_epochs,
    callbacks=callbacks
)

# Save final model
model.save('/content/drive/MyDrive/resnet152_dog_emotion_final.h5')

"""---

## Step 5: Evaluate and Visualize Results"""

# Cell 5: Evaluate and Visualize
# Combine histories
acc = history.history['accuracy'] + history_fine.history['accuracy']
val_acc = history.history['val_accuracy'] + history_fine.history['val_accuracy']
loss = history.history['loss'] + history_fine.history['loss']
val_loss = history.history['val_loss'] + history_fine.history['val_loss']

# Plot accuracy and loss
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Evaluate on validation set
val_loss, val_accuracy = model.evaluate(val_generator)
print(f"Validation Loss: {val_loss:.4f}")
print(f"Validation Accuracy: {val_accuracy:.4f}")

# Confusion matrix
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
val_generator.reset()
preds = np.argmax(model.predict(val_generator), axis=1)
true_labels = val_generator.classes
cm = confusion_matrix(true_labels, preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

"""---

## Optional: Test a Single Image"""

# Cell 6: Test a Single Image
from tensorflow.keras.preprocessing.image import load_img, img_to_array

def predict_image(image_path):
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img)
    img_array = tf.keras.applications.resnet.preprocess_input(img_array)
    img_array = np.expand_dims(img_array, axis=0)
    pred = model.predict(img_array)
    predicted_class = class_names[np.argmax(pred)]
    return img, predicted_class

# Example usage
test_image_path = '/content/drive/MyDrive/Arwan IRIS/2-EMOTION_IMAGE_DATASET/dog_emotion_image_1_alert/sample.jpg'  # Update path
img, pred_class = predict_image(test_image_path)
plt.imshow(img)
plt.title(f"Predicted: {pred_class}")
plt.axis('off')
plt.show()

"""---

## Step 6: Convert to TensorFlow Lite for Edge Deployment"""

# Cell 6: TensorFlow Lite Conversion
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Apply default optimizations (quantization)
converter.target_spec.supported_types = [tf.float16]  # Use float16 for reduced size
tflite_model = converter.convert()

# Save the TFLite model
tflite_path = '/content/drive/MyDrive/resnet152_dog_emotion.tflite'
with open(tflite_path, 'wb') as f:
    f.write(tflite_model)

print(f"TFLite model saved to {tflite_path}")
print(f"Size of TFLite model: {os.path.getsize(tflite_path) / (1024 * 1024):.2f} MB")

# Test TFLite inference
interpreter = tf.lite.Interpreter(model_path=tflite_path)
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Example inference on a single image
test_image = load_img(test_image_path, target_size=(224, 224))
test_image_array = img_to_array(test_image)
test_image_array = tf.keras.applications.resnet.preprocess_input(test_image_array)
test_image_array = np.expand_dims(test_image_array, axis=0).astype(np.float32)

interpreter.set_tensor(input_details[0]['index'], test_image_array)
interpreter.invoke()
tflite_output = interpreter.get_tensor(output_details[0]['index'])
tflite_pred_class = class_names[np.argmax(tflite_output[0])]
print(f"TFLite Predicted Class: {tflite_pred_class}")
plt.imshow(test_image)
plt.title(f"TFLite Predicted: {tflite_pred_class}")
plt.axis('off')
plt.show()

"""---

## Notes

1. **Dataset**: Ensure the dataset is structured with subfolders for each emotion class (e.g., `dog_emotion_image_1_alert`, `dog_emotion_image_2_pain`, etc.).
2. **GPU**: Enable GPU in Colab for faster training.
3. **Fine-tuning**: Fine-tuning the last 20 layers of ResNet152 improves accuracy for dog emotion classification.
4. **Evaluation**: Use advanced metrics (e.g., precision, recall, F1-score) for a comprehensive evaluation.

---

## Expected Results

- **Accuracy**: ResNet152 typically achieves >90% accuracy on image classification tasks with fine-tuning.
- **TFLite Model**: The TFLite model is optimized for edge deployment with minimal loss in accuracy.

"""

---

This enhanced notebook is ready for deployment and can be run in Google Colab with GPU support. Adjust paths and parameters as needed for your specific dataset.